{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Juan Pablo Fonseca Correa\n",
    "### 138263"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importar librerías y leer la base de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sys import maxint\n",
    "from math import pow\n",
    "from math import fabs\n",
    "from __future__ import division\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from random import uniform\n",
    "df = pd.read_csv('regLinPoli.csv') # leo la bd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\juanpa~1\\desktop\\env1\\python~1\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# separar en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df[df.columns[0:-1]],df[df.columns[-1]], train_size=0.75)\n",
    "p = len(X_train.columns)\n",
    "\n",
    "# tengo que estandarizarlos\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_sc=scaler.transform(X_train)\n",
    "X_test_sc=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Vap(x, coeff):\n",
    "    vap = 0\n",
    "    for i in range(0,p+1):\n",
    "        vap += coeff[i]*x[i]\n",
    "    return vap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error(coeff):\n",
    "    y = coeff[0]\n",
    "    for i in range(0,p):\n",
    "        y += coeff[i+1]*X_train_sc[:,i]\n",
    "    errores = [pow(y[i]-Y_train.iloc[i],2) for i in range(0,len(Y_train.values))]\n",
    "    error = sum(errores)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lambda = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w's estandarizadas:\n",
      "w[0]: 3030.51672603\n",
      "\n",
      "w[1]: 1168.95821256\n",
      "\n",
      "w[2]: 1632.43633\n",
      "\n",
      "w[3]: 30.6629996876\n",
      "\n",
      "w[4]: 25.0828391317\n",
      "\n",
      "w[5]: 27.2603888985\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w = [uniform(-5,5) for i in range(0,p+1)]\n",
    "eta = 0.005\n",
    "lamb = 0\n",
    "errores =[]\n",
    "for i in range (0,len(X_train)):\n",
    "    xi0 = [1]\n",
    "    xidemas=[X_train_sc[i][j] for j in range(0,p)]\n",
    "    xi = xi0 + xidemas\n",
    "    yi = Y_train.iloc[i]\n",
    "    error_actual = yi - Vap(xi,w)\n",
    "    errores.append(error(w))\n",
    "    # actualizas UNA vez para el dato i\n",
    "    for j in range(len(w)):\n",
    "        w[j] = w[j] + eta * error_actual * xi[j] - lamb * w[j]\n",
    "\n",
    "    # IMPRIMIR CADA ITERACIÓN\n",
    "    # print \"Error actual: {0}\".format(error_actual)\n",
    "    # print \"Iteración {0}:\".format(i+1)\n",
    "    # for j in range(len(w)):\n",
    "    #     print \"w{0} = {1}   \".format(j,w[j])\n",
    "    # print \"\"\n",
    "# Muestro las w's\n",
    "print \"w's estandarizadas:\"\n",
    "for i in range(0,p+1):\n",
    "    print 'w[{0}]: {1}\\n'.format(i,w[i])\n",
    "print \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suma de los errores al cuadrado:  30431346.5285\n"
     ]
    }
   ],
   "source": [
    "err = 0\n",
    "for i in range(0,len(X_test_sc)):\n",
    "    dif = Y_test.iloc[i] - Vap([1]+X_test_sc[i].tolist(),w)\n",
    "    err += dif*dif\n",
    "print \"Suma de los errores al cuadrado: \", err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lambda = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w's estandarizadas:\n",
      "w[0]: 971.264807566\n",
      "\n",
      "w[1]: 548.514169093\n",
      "\n",
      "w[2]: 618.045851146\n",
      "\n",
      "w[3]: 324.278649556\n",
      "\n",
      "w[4]: -95.8172762436\n",
      "\n",
      "w[5]: -8.75453492174\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w = [uniform(-5,5) for i in range(0,p+1)]\n",
    "eta = 0.005\n",
    "lamb = 0.01\n",
    "errores =[]\n",
    "for i in range (0,len(X_train)):\n",
    "    xi0 = [1]\n",
    "    xidemas=[X_train_sc[i][j] for j in range(0,p)]\n",
    "    xi = xi0 + xidemas\n",
    "    yi = Y_train.iloc[i]\n",
    "    error_actual = yi - Vap(xi,w)\n",
    "    errores.append(error(w))\n",
    "    # actualizas UNA vez para el dato i\n",
    "    for j in range(len(w)):\n",
    "        w[j] = w[j] + eta * error_actual * xi[j] - lamb * w[j]\n",
    "\n",
    "    # IMPRIMIR CADA ITERACIÓN\n",
    "    # print \"Error actual: {0}\".format(error_actual)\n",
    "    # print \"Iteración {0}:\".format(i+1)\n",
    "    # for j in range(len(w)):\n",
    "    #     print \"w{0} = {1}   \".format(j,w[j])\n",
    "    # print \"\"\n",
    "# Muestro las w's\n",
    "print \"w's estandarizadas:\"\n",
    "for i in range(0,p+1):\n",
    "    print 'w[{0}]: {1}\\n'.format(i,w[i])\n",
    "print \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se observa que con una lambda mayor a cero, los valores de las w's que antes estaban en el orden de los miles, ahora ya están en el orden de las centanas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suma de los errores al cuadrado:  1831694326.38\n"
     ]
    }
   ],
   "source": [
    "err = 0\n",
    "for i in range(0,len(X_test_sc)):\n",
    "    dif = Y_test.iloc[i] - Vap([1]+X_test_sc[i].tolist(),w)\n",
    "    err += dif*dif\n",
    "print \"Suma de los errores al cuadrado: \", err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Se puede ver que los errores se disparan drásticamente utilizando la lambda = 0.01 en comparación a la lambda = 0. Sin embargo, debe haber casos en los que sí sea preferible usar lambda = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
